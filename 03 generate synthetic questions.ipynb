{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cda91e8b-8924-45a0-b1a3-d5e17e5a0041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%set_env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78a58ca2-43df-41ee-be69-781577d1b90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-26 10:33:11 llm_engine.py:176] Initializing an LLM engine (v0.5.3.post1) with config: model='neuralmagic/Mistral-Nemo-Instruct-2407-FP8', speculative_config=None, tokenizer='neuralmagic/Mistral-Nemo-Instruct-2407-FP8', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=16384, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=fp8, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None), seed=0, served_model_name=neuralmagic/Mistral-Nemo-Instruct-2407-FP8, use_v2_block_manager=False, enable_prefix_caching=False)\n",
      "INFO 07-26 10:33:12 model_runner.py:680] Starting to load model neuralmagic/Mistral-Nemo-Instruct-2407-FP8...\n",
      "WARNING 07-26 10:33:12 fp8.py:39] Detected fp8 checkpoint. Please note that the format is experimental and subject to change.\n",
      "INFO 07-26 10:33:12 weight_utils.py:223] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "787c51e45db148f1bb0b3ea3fdc0af01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-26 10:33:15 model_runner.py:692] Loading model weights took 12.9013 GB\n",
      "INFO 07-26 10:33:17 gpu_executor.py:102] # GPU blocks: 10016, # CPU blocks: 1638\n",
      "INFO 07-26 10:33:18 model_runner.py:980] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 07-26 10:33:18 model_runner.py:984] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 07-26 10:33:25 model_runner.py:1181] Graph capturing finished in 7 secs.\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"neuralmagic/Mistral-Nemo-Instruct-2407-FP8\"\n",
    "llm = LLM(model_id, max_model_len=16384)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9c2ac15-bfb6-444c-a629-9b16d14b80ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nI will provide you a piece of text. Try to think of a question to which the piece of text would be a suitable answer.\\n```\\n{answer}\\n```\\n\\nExplain your reasoning.\\nThen return your final question on a new line starting with \"QUESTION: \"\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "I will provide you a piece of text. Try to think of a question to which the piece of text would be a suitable answer.\n",
    "```\n",
    "{answer}\n",
    "```\n",
    "\n",
    "Explain your reasoning.\n",
    "Then return your final question on a new line starting with \"QUESTION: \"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b45bbeb7-eb06-4e29-9bbe-11e0278f47ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "\n",
    "datadir = Path(\"data\")\n",
    "ds_answers = load_dataset(\n",
    "    \"json\", data_files=str(datadir.joinpath(\"interim\", \"answers.jsonl\"))\n",
    ")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bf0f7a8-916d-4f37-b34b-99e43c2e3d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "I will provide you a piece of text. Try to think of a question to which the piece of text would be a suitable answer.\n",
    "```\n",
    "{answer}\n",
    "```\n",
    "\n",
    "Explain your reasoning.\n",
    "Then return your final question on a new line starting with \"QUESTION: \"\n",
    "\"\"\"\n",
    "\n",
    "def generate_prompt(paragraph):\n",
    "    return tokenizer.apply_chat_template(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": \"You are an imaginative assistant.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt_template.format(answer=paragraph),\n",
    "            },\n",
    "        ],\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "\n",
    "test_prompt = generate_prompt(ds_answers[0][\"paragraph\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "94d5187f-4892-448f-966b-9af28aa7410b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████| 10797/10797 [14:55<00:00, 12.05it/s, est. speed input: 3853.95 toks/s, output: 1603.68 toks/s]\n"
     ]
    }
   ],
   "source": [
    "sampling_params = SamplingParams(max_tokens=8192)\n",
    "prompts = [generate_prompt(rec[\"paragraph\"]) for rec in ds_answers]\n",
    "request_outputs = llm.generate(prompts, sampling_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "99c7011a-8597-4d2f-94b0-6f4cde1a45bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_responses = [ro.outputs[0].text for ro in request_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "77681a9a-d848-4ea8-92fd-f3b0df18e2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QUESTION:        7135\n",
       "**QUESTION:**    1594\n",
       "\"QUESTION:        807\n",
       "**QUESTION:       377\n",
       "**Question:**      79\n",
       "                 ... \n",
       "\"If                 1\n",
       "\"As                 1\n",
       "\"WHERE              1\n",
       "Or,                 1\n",
       "(QUESTION:          1\n",
       "Name: count, Length: 155, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.Series(llm_responses).apply(lambda x: x.split(\"\\n\")[-1]).apply(lambda x: x.split(\" \")[0]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1f3cbe58-dc23-4753-8edd-dba6c39debeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_llm = ds_answers.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d1b6c5a0-f8d2-4213-829d-1fd0dc37924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_llm[\"response\"] = llm_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2c5803c5-578c-4ac9-9e92-e6e49f947279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prefix</th>\n",
       "      <th>paragraph_index</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N14342</td>\n",
       "      <td>178</td>\n",
       "      <td>This harangue did but increase their consterna...</td>\n",
       "      <td>**Reasoning:** This text describes a military ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N20751</td>\n",
       "      <td>738</td>\n",
       "      <td>I was greatly edified the other day in paying ...</td>\n",
       "      <td>Based on the text, an appropriate question cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N04486</td>\n",
       "      <td>77</td>\n",
       "      <td>65. But in a Circle* drawn from one Body, as a...</td>\n",
       "      <td>Based on the provided text, it discusses the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N19918</td>\n",
       "      <td>280</td>\n",
       "      <td>What you offer, replied I, is nothing but soph...</td>\n",
       "      <td>The author's reasoning seems to be a response ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N04182</td>\n",
       "      <td>136</td>\n",
       "      <td>Having thus, in as plain a Manner as I could, ...</td>\n",
       "      <td>**Reasoning:**\\n\\nThe text discusses the autho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prefix  paragraph_index                                          paragraph  \\\n",
       "0  N14342              178  This harangue did but increase their consterna...   \n",
       "1  N20751              738  I was greatly edified the other day in paying ...   \n",
       "2  N04486               77  65. But in a Circle* drawn from one Body, as a...   \n",
       "3  N19918              280  What you offer, replied I, is nothing but soph...   \n",
       "4  N04182              136  Having thus, in as plain a Manner as I could, ...   \n",
       "\n",
       "                                            response  \n",
       "0  **Reasoning:** This text describes a military ...  \n",
       "1  Based on the text, an appropriate question cou...  \n",
       "2  Based on the provided text, it discusses the p...  \n",
       "3  The author's reasoning seems to be a response ...  \n",
       "4  **Reasoning:**\\n\\nThe text discusses the autho...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_llm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "10b6357a-02a2-4d3e-a47c-6264688576a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        **QUESTION:**\n",
       "1            QUESTION:\n",
       "2            QUESTION:\n",
       "3            QUESTION:\n",
       "4        **QUESTION:**\n",
       "             ...      \n",
       "10792        QUESTION:\n",
       "10793       \"QUESTION:\n",
       "10794    **QUESTION:**\n",
       "10795        QUESTION:\n",
       "10796        QUESTION:\n",
       "Name: response, Length: 10797, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_llm[\"response\"].apply(lambda x: x.split(\"\\n\")[-1]).apply(lambda x: x.split(\" \")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a7ad2850-4a49-49da-9612-4ca835f08424",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_rows = df_llm[\"response\"].apply(lambda x: x.split(\"\\n\")[-1]).apply(lambda x: x.split(\" \")[0]).isin([\"QUESTION:\", \"**QUESTION:**\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5919ce12-898d-4d53-a33c-ca9191303185",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected = df_llm[selected_rows].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f5329c1-2d36-4633-8fe5-d6eec42b354d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prefix</th>\n",
       "      <th>paragraph_index</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N14342</td>\n",
       "      <td>178</td>\n",
       "      <td>This harangue did but increase their consterna...</td>\n",
       "      <td>**Reasoning:** This text describes a military ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N20751</td>\n",
       "      <td>738</td>\n",
       "      <td>I was greatly edified the other day in paying ...</td>\n",
       "      <td>Based on the text, an appropriate question cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N04486</td>\n",
       "      <td>77</td>\n",
       "      <td>65. But in a Circle* drawn from one Body, as a...</td>\n",
       "      <td>Based on the provided text, it discusses the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N19918</td>\n",
       "      <td>280</td>\n",
       "      <td>What you offer, replied I, is nothing but soph...</td>\n",
       "      <td>The author's reasoning seems to be a response ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N04182</td>\n",
       "      <td>136</td>\n",
       "      <td>Having thus, in as plain a Manner as I could, ...</td>\n",
       "      <td>**Reasoning:**\\n\\nThe text discusses the autho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prefix  paragraph_index                                          paragraph  \\\n",
       "0  N14342              178  This harangue did but increase their consterna...   \n",
       "1  N20751              738  I was greatly edified the other day in paying ...   \n",
       "2  N04486               77  65. But in a Circle* drawn from one Body, as a...   \n",
       "3  N19918              280  What you offer, replied I, is nothing but soph...   \n",
       "4  N04182              136  Having thus, in as plain a Manner as I could, ...   \n",
       "\n",
       "                                            response  \n",
       "0  **Reasoning:** This text describes a military ...  \n",
       "1  Based on the text, an appropriate question cou...  \n",
       "2  Based on the provided text, it discusses the p...  \n",
       "3  The author's reasoning seems to be a response ...  \n",
       "4  **Reasoning:**\\n\\nThe text discusses the autho...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_selected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3d9fc14d-d251-43f9-90f5-0af497edc8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "question_pattern = re.compile(r'(?s).*?(?:\\*\\*QUESTION:\\*\\*|QUESTION:)\\s*(.*)')\n",
    "\n",
    "df_selected[\"question\"] = df_selected[\"response\"].apply(lambda x: question_pattern.search(x).group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c128644a-1565-4da7-9622-5e361ef2a780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prefix</th>\n",
       "      <th>paragraph_index</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>response</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N14342</td>\n",
       "      <td>178</td>\n",
       "      <td>This harangue did but increase their consterna...</td>\n",
       "      <td>**Reasoning:** This text describes a military ...</td>\n",
       "      <td>What did the American soldiers see happening w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N20751</td>\n",
       "      <td>738</td>\n",
       "      <td>I was greatly edified the other day in paying ...</td>\n",
       "      <td>Based on the text, an appropriate question cou...</td>\n",
       "      <td>What critique did the Quaker have about the Ep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N04486</td>\n",
       "      <td>77</td>\n",
       "      <td>65. But in a Circle* drawn from one Body, as a...</td>\n",
       "      <td>Based on the provided text, it discusses the p...</td>\n",
       "      <td>What is the gravitational force experienced by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N19918</td>\n",
       "      <td>280</td>\n",
       "      <td>What you offer, replied I, is nothing but soph...</td>\n",
       "      <td>The author's reasoning seems to be a response ...</td>\n",
       "      <td>What are the principles discussed in the text ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N04182</td>\n",
       "      <td>136</td>\n",
       "      <td>Having thus, in as plain a Manner as I could, ...</td>\n",
       "      <td>**Reasoning:**\\n\\nThe text discusses the autho...</td>\n",
       "      <td>What misconceptions about the nature of a \"Wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10791</th>\n",
       "      <td>N15939</td>\n",
       "      <td>15</td>\n",
       "      <td>THE text therefore, and the great occasion, on...</td>\n",
       "      <td>Reasoning: The provided text appears to be an ...</td>\n",
       "      <td>How does the speaker believe a strong civil un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10792</th>\n",
       "      <td>N06545</td>\n",
       "      <td>453</td>\n",
       "      <td>This Meeting (as before mentioned) being gener...</td>\n",
       "      <td>**Reasoning:**\\n\\nThe text appears to be a tra...</td>\n",
       "      <td>How did George Keith respond to the speaker's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10794</th>\n",
       "      <td>N27874</td>\n",
       "      <td>12</td>\n",
       "      <td>The WHITE LOAF.\\nONE day, it was about the mid...</td>\n",
       "      <td>**Explanation:**\\n\\nThe text describes a situa...</td>\n",
       "      <td>What had Mrs. White intended to use the small ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10795</th>\n",
       "      <td>N17823</td>\n",
       "      <td>795</td>\n",
       "      <td>Being now about church matters, I will here in...</td>\n",
       "      <td>The text describes a disagreement among church...</td>\n",
       "      <td>How was the dispute over the location of the n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10796</th>\n",
       "      <td>N28815</td>\n",
       "      <td>1127</td>\n",
       "      <td>The subject was too painful to be long endured...</td>\n",
       "      <td>The text suggests that Lord Mortimer decided t...</td>\n",
       "      <td>What was the painful subject that Lord Mortime...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8729 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       prefix  paragraph_index  \\\n",
       "0      N14342              178   \n",
       "1      N20751              738   \n",
       "2      N04486               77   \n",
       "3      N19918              280   \n",
       "4      N04182              136   \n",
       "...       ...              ...   \n",
       "10791  N15939               15   \n",
       "10792  N06545              453   \n",
       "10794  N27874               12   \n",
       "10795  N17823              795   \n",
       "10796  N28815             1127   \n",
       "\n",
       "                                               paragraph  \\\n",
       "0      This harangue did but increase their consterna...   \n",
       "1      I was greatly edified the other day in paying ...   \n",
       "2      65. But in a Circle* drawn from one Body, as a...   \n",
       "3      What you offer, replied I, is nothing but soph...   \n",
       "4      Having thus, in as plain a Manner as I could, ...   \n",
       "...                                                  ...   \n",
       "10791  THE text therefore, and the great occasion, on...   \n",
       "10792  This Meeting (as before mentioned) being gener...   \n",
       "10794  The WHITE LOAF.\\nONE day, it was about the mid...   \n",
       "10795  Being now about church matters, I will here in...   \n",
       "10796  The subject was too painful to be long endured...   \n",
       "\n",
       "                                                response  \\\n",
       "0      **Reasoning:** This text describes a military ...   \n",
       "1      Based on the text, an appropriate question cou...   \n",
       "2      Based on the provided text, it discusses the p...   \n",
       "3      The author's reasoning seems to be a response ...   \n",
       "4      **Reasoning:**\\n\\nThe text discusses the autho...   \n",
       "...                                                  ...   \n",
       "10791  Reasoning: The provided text appears to be an ...   \n",
       "10792  **Reasoning:**\\n\\nThe text appears to be a tra...   \n",
       "10794  **Explanation:**\\n\\nThe text describes a situa...   \n",
       "10795  The text describes a disagreement among church...   \n",
       "10796  The text suggests that Lord Mortimer decided t...   \n",
       "\n",
       "                                                question  \n",
       "0      What did the American soldiers see happening w...  \n",
       "1      What critique did the Quaker have about the Ep...  \n",
       "2      What is the gravitational force experienced by...  \n",
       "3      What are the principles discussed in the text ...  \n",
       "4      What misconceptions about the nature of a \"Wor...  \n",
       "...                                                  ...  \n",
       "10791  How does the speaker believe a strong civil un...  \n",
       "10792  How did George Keith respond to the speaker's ...  \n",
       "10794  What had Mrs. White intended to use the small ...  \n",
       "10795  How was the dispute over the location of the n...  \n",
       "10796  What was the painful subject that Lord Mortime...  \n",
       "\n",
       "[8729 rows x 5 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "83e43122-ec7e-48e4-a10b-d1ebf06fd141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        {'conversations': [{'from': 'system', 'value':...\n",
       "1        {'conversations': [{'from': 'system', 'value':...\n",
       "2        {'conversations': [{'from': 'system', 'value':...\n",
       "3        {'conversations': [{'from': 'system', 'value':...\n",
       "4        {'conversations': [{'from': 'system', 'value':...\n",
       "                               ...                        \n",
       "10791    {'conversations': [{'from': 'system', 'value':...\n",
       "10792    {'conversations': [{'from': 'system', 'value':...\n",
       "10794    {'conversations': [{'from': 'system', 'value':...\n",
       "10795    {'conversations': [{'from': 'system', 'value':...\n",
       "10796    {'conversations': [{'from': 'system', 'value':...\n",
       "Length: 8729, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt = \"You are a helpful assistant that answers in the style of early American written sources\"\n",
    "\n",
    "def row_to_jsonline(row):\n",
    "    conversations = []\n",
    "    conversations.append({\"from\": \"system\", \"value\": system_prompt})\n",
    "    conversations.append({\"from\": \"human\", \"value\": row[\"question\"]})\n",
    "    conversations.append({\"from\": \"gpt\", \"value\": row[\"paragraph\"]})\n",
    "    return {\"conversations\": conversations}\n",
    "\n",
    "df_selected.apply(row_to_jsonline, axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4b923b98-f0eb-455e-b501-b0b9435ba1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with datadir.joinpath(\"interim\", \"chatbot_train_data.jsonl\").open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for example in df_selected.apply(row_to_jsonline, axis=1):\n",
    "        f.write(json.dumps(example) + \"\\n\")\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2020c095-41a2-4f91-8584-2b8a3942b8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m{\n",
      "  \u001b[0m\u001b[34;1m\"conversations\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
      "    \u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"from\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"system\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"value\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"You are a helpful assistant that answers in the style of early American written sources\"\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"from\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"human\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"value\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"What did the American soldiers see happening when they started firing their batteries?\"\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"from\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"gpt\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"value\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"This harangue did but increase their consternation. As soon as they began to\\nhear the terrible roaring of our batteries, we that were on the heights saw\\nthem flying precipitately from their redoubts, while their batteries in an\\ninstant were entirely silenced. They had been quiet spectators of our labors,\\nand we now became so in our turn with respect to them. At this time I watched\\nan opportunity to traverse our lines, which consisted of a large ditch, broad\\nenough for carriages to travel in, about four feet in depth, and covered by a\\nrampart of gabions, or cylindrical baskets, fixed upon the ground, by means of\\nprojecting stakes, filled and covered over with loose dirt, and forming a\\nheight of about seven feet on the side toward the enemy. The batteries were\\nplaced upon platforms, on the inside of the ditch, raised and strengthened with\\npalisadoes. The quarter next the enemy was covered by a large parapet, in which\\nwere the embrasures for the cannon: all these works, as well as most of those\\nof the English consisted wholly of earth.\"\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m]\u001b[0m\u001b[1;39m\n",
      "\u001b[1;39m}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!head -n1 data/interim/chatbot_train_data.jsonl | jq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc8fd4c-9639-45a3-ae25-68ed37899b63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eam-bot",
   "language": "python",
   "name": "eam-bot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
